import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, models, transforms
from torch.utils.data import DataLoader, random_split
import matplotlib.pyplot as plt
import os
import time

# 1. è¨­å®šåƒæ•¸
BATCH_SIZE = 32  # æ‚¨çš„ 5060 Ti å¤ å¼·ï¼Œå¯ä»¥è¨­ 32 æˆ– 64 åŠ å¿«é€Ÿåº¦
LEARNING_RATE = 0.001
EPOCHS = 20      # å»ºè­°ç·´ 20 è¼ª
DATA_DIR = './traindata' # æŒ‡å‘æ‚¨çš„æ‰‹æŒ‡è³‡æ–™å¤¾
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def train_model():
    print(f"ğŸš€ ä½¿ç”¨è£ç½®: {DEVICE}")
    if torch.cuda.is_available():
        print(f"   é¡¯ç¤ºå¡å‹è™Ÿ: {torch.cuda.get_device_name(0)}")

    # 2. åœ–ç‰‡é è™•ç† (ResNet æ¨™æº–è™•ç†æµç¨‹)
    data_transforms = transforms.Compose([
        transforms.Resize((224, 224)),       # ResNet éœ€è¦ 224x224
        transforms.RandomHorizontalFlip(),   # [æ–°å¢] è³‡æ–™å¢å¼·ï¼šéš¨æ©Ÿå·¦å³ç¿»è½‰
        transforms.RandomRotation(15),       # [æ–°å¢] è³‡æ–™å¢å¼·ï¼šéš¨æ©Ÿæ—‹è½‰
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    # 3. è®€å–è³‡æ–™
    if not os.path.exists(DATA_DIR):
        print(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° {DATA_DIR} è³‡æ–™å¤¾ï¼")
        return

    dataset = datasets.ImageFolder(DATA_DIR, transform=data_transforms)
    
    # è‡ªå‹•åµæ¸¬é¡åˆ¥æ•¸é‡
    class_names = dataset.classes
    num_classes = len(class_names)
    print(f"ğŸ“‚ åµæ¸¬åˆ°çš„é¡åˆ¥: {class_names} (å…± {num_classes} é¡)")

    # åˆ†å‰² 80% è¨“ç·´, 20% é©—è­‰
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_data, val_data = random_split(dataset, [train_size, val_size])

    train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)

    print(f"ğŸ“Š è¨“ç·´åœ–ç‰‡: {len(train_data)} å¼µ, é©—è­‰åœ–ç‰‡: {len(val_data)} å¼µ")

    # 4. å»ºç«‹æ¨¡å‹ (ä½¿ç”¨é è¨“ç·´çš„ ResNet18)
    # weights='IMAGENET1K_V1' æ˜¯æ–°ç‰ˆå¯«æ³•ï¼Œå–ä»£ pretrained=True
    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
    
    # ä¿®æ”¹æœ€å¾Œä¸€å±¤å…¨é€£æ¥å±¤ (Fully Connected Layer)
    num_ftrs = model.fc.in_features
    model.fc = nn.Linear(num_ftrs, num_classes) # ä¿®æ”¹è¼¸å‡ºç‚º 6 (0~5)
    
    model = model.to(DEVICE)

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)

    # 5. é–‹å§‹è¨“ç·´
    train_acc_history = []
    val_acc_history = []
    
    start_time = time.time()

    for epoch in range(EPOCHS):
        # --- è¨“ç·´éšæ®µ ---
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        for inputs, labels in train_loader:
            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        epoch_acc = 100 * correct / total
        epoch_loss = running_loss / len(train_loader)
        train_acc_history.append(epoch_acc)

        # --- é©—è­‰éšæ®µ (æ–°å¢çš„éƒ¨åˆ†ï¼Œæª¢æŸ¥è€ƒè©¦æˆç¸¾) ---
        model.eval() # è¨­å®šç‚ºè©•ä¼°æ¨¡å¼
        val_correct = 0
        val_total = 0
        with torch.no_grad(): # é©—è­‰æ™‚ä¸éœ€è¦ç®—æ¢¯åº¦ï¼Œçœè¨˜æ†¶é«”
            for inputs, labels in val_loader:
                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)
                outputs = model(inputs)
                _, predicted = torch.max(outputs.data, 1)
                val_total += labels.size(0)
                val_correct += (predicted == labels).sum().item()
        
        val_acc = 100 * val_correct / val_total
        val_acc_history.append(val_acc)
        
        print(f"Epoch {epoch+1}/{EPOCHS} | Loss: {epoch_loss:.4f} | è¨“ç·´ Acc: {epoch_acc:.2f}% | é©—è­‰ Acc: {val_acc:.2f}%")

    time_elapsed = time.time() - start_time
    print(f"\nâœ… è¨“ç·´å®Œæˆï¼è€—æ™‚: {time_elapsed // 60:.0f}åˆ† {time_elapsed % 60:.0f}ç§’")

    # 6. å„²å­˜æ¨¡å‹
    torch.save(model.state_dict(), 'finger_model_pytorch.pth')
    print("ğŸ’¾ æ¨¡å‹å·²å„²å­˜ç‚º finger_model_pytorch.pth")

    # 7. ç•«åœ–
    plt.figure(figsize=(10, 5))
    plt.plot(train_acc_history, label='Train Accuracy')
    plt.plot(val_acc_history, label='Validation Accuracy')
    plt.title('Training vs Validation Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy (%)')
    plt.legend()
    plt.grid(True)
    plt.savefig('result_chart_pytorch.png')
    print("ğŸ“ˆ åœ–è¡¨å·²å„²å­˜ç‚º result_chart_pytorch.png")

if __name__ == '__main__':
    train_model()